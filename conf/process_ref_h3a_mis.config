/*
 * -------------------------------------------------
 * h3achipimputation Nextflow config file
 * -------------------------------------------------
 * Default config options for all environments.
 * Cluster-specific config options should be saved
 * in the conf folder and imported under a profile
 * name here.
 */

// Global default params, used in configs
params {

  version         = '1.0'
  // container       = 'docker://quay.io/h3abionet_org/imputation_tools' // Container slug. Stable releases should specify release tag!
  clusterOptions  = false
  help            = false

  chromosomes     = [ 22 ] // Impute all chromosomes by default
  project_name    = "h3a_mis" // Default project name
  outdir          = "/cbio/dbs/refpanels/H3AR3b/1.0.0" // outDir: where to put all pipeline's outputs

  refpanels = [
    ["testRefPanel", "/users/mamana/refimpute/testdata_imputation/refPanel_testdata_%s_phased.vcf.gz"]
  ]

  datasets = [ 
    // ['threesamples', "/users/mamana/refimpute/testdata_imputation/target_testdata.vcf.gz"]
  ]

  // Genetic map for eagle2
  eagle_genetic_map = "/users/mamana/refimpute/testdata_imputation/genetic_map_hg19_withX_testdata.txt.gz"

  // Minimac4 option
  minRatio = '0.01'
  chunk = ''
}

// process.container = 'docker://quay.io/h3abionet_org/imputation_tools' // Container slug. Stable releases should specify release tag!
process {
    // Process-specific resource requirements
    withLabel: 'medium' {
        memory = 6.GB
    }
    withLabel : 'bigmem' {
        memory = 30.GB
    }
}

profiles {
  singularity {
    singularity.enabled = true
    singularity.autoMounts = true
    process.container = 'docker://quay.io/h3abionet_org/imputation_tools'
  }
  slurm {
    process.executor = 'slurm'
  }
}

// Capture exit codes from upstream processes when piping
process.shell = ['/bin/bash', '-euo', 'pipefail']

manifest {
  name = 'h3achipimputation'
  description = 'imputation'
  homePage = 'https://github.com/h3abionet/chipimputation'
  mainScript = 'main.nf'
  version = '>=24.04.1'
}

// Function to ensure that resource requirements don't go beyond
// a maximum limit
def check_max(obj, type) {
  if(type == 'memory'){
    try {
      if(obj.compareTo(params.max_memory as nextflow.util.MemoryUnit) == 1)
        return params.max_memory as nextflow.util.MemoryUnit
      else
        return obj
    } catch (all) {
      println "   ### ERROR ###   Max memory '${params.max_memory}' is not valid! Using default value: $obj"
      return obj
    }
  } else if(type == 'time'){
    try {
      if(obj.compareTo(params.max_time as nextflow.util.Duration) == 1)
        return params.max_time as nextflow.util.Duration
      else
        return obj
    } catch (all) {
      println "   ### ERROR ###   Max time '${params.max_time}' is not valid! Using default value: $obj"
      return obj
    }
  } else if(type == 'cpus'){
    try {
      return Math.min( obj, params.max_cpus as int )
    } catch (all) {
      println "   ### ERROR ###   Max cpus '${params.max_cpus}' is not valid! Using default value: $obj"
      return obj
    }
  }
}

workflow.onComplete = {
  println "========================================="
  println "Pipeline completed at: $workflow.complete"
  println "Execution status: ${ workflow.success ? 'OK' : 'failed' }"
}
